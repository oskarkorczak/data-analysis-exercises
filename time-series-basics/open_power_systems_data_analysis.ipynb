{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "open-power-systems-data-analysis.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "UHSQ2bjbYrY7"
      },
      "source": [
        "# Data analysis based on below tutorial:\n",
        "# https://www.dataquest.io/blog/tutorial-time-series-analysis-with-pandas/\n",
        "\n",
        "# Data refers to electricity production and consumption for 2006-2017 reported, as daily totals in gigawatt-hours (GWh).\n",
        "\n",
        "# The columns of the data file are:\n",
        "# Date — The date (yyyy-mm-dd format)\n",
        "# Consumption — Electricity consumption in GWh\n",
        "# Wind — Wind power production in GWh\n",
        "# Solar — Solar power production in GWh\n",
        "# Wind+Solar — Sum of wind and solar power production in GWh"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ySgxFxj_cDLu"
      },
      "source": [
        "# Imports\n",
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HIwzds0M_W5C"
      },
      "source": [
        "# WHAT IS AN INDEX IN DATA FRAME\n",
        "# Playing with Timestamp structure, as a basic foundation of Time Series\n",
        "\n",
        "# pd.to_datetime('2018-01-15 3:45pm')\n",
        "# pd.to_datetime('7/8/1952')\n",
        "# pd.to_datetime('7/8/1952', dayfirst=True)\n",
        "# pd.to_datetime(['2018-01-05', '7/8/1952', 'Oct 10, 1995'])\n",
        "pd.to_datetime(['2/25/10', '8/6/17', '12/15/12'], format='%m/%d/%y')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h5Wp6HnP_g3X"
      },
      "source": [
        "# Upload data\n",
        "from google.colab import files\n",
        "files.upload()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nXo9BPwPCWJf"
      },
      "source": [
        "# Read data in (look out for the name after the upload)\n",
        "df = pd.read_csv('opsd_germany_daily.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FGSpaBOyAW2I"
      },
      "source": [
        "# Check data matrix dimensions and few data samples\n",
        "df.shape\n",
        "df.head(3)\n",
        "df.tail(3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X2nPiVQqBIsw"
      },
      "source": [
        "# Check column types and SET INDEX on \"Date\"\n",
        "df.dtypes\n",
        "\n",
        "# \"Date\" column should be in \"datetime64[ns]\" type, but it's object instead. \n",
        "# I will try to set up an index on \"Date\" field anyway. \n",
        "# df = df.set_index('Date') # Needs to be an operation run once\n",
        "df.dtypes\n",
        "df.head(3)\n",
        "df.index\n",
        "\n",
        "# PRO TIP:\n",
        "# Usually above steps for setting an index could be compressed to below line:\n",
        "# df = pd.read_csv('opsd_germany_daily.csv', index_col=0, parse_dates=True)\n",
        "\n",
        "# I will use PRO TIP method, as it gives data frame with correct index type\n",
        "df = pd.read_csv('opsd_germany_daily.csv', index_col=0, parse_dates=True)\n",
        "df.dtypes\n",
        "df.index"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EFUtNsogA24o"
      },
      "source": [
        "# Add to data frame few individual index components\n",
        "df['Year'] = df.index.year\n",
        "df['Month'] = df.index.month\n",
        "df['Weekday Name'] = df.index.day_name()\n",
        "\n",
        "df.sample(5, random_state=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I3ACWPnlLfGc"
      },
      "source": [
        "# READ INDEX\n",
        "\n",
        "# Get particular point in time\n",
        "df.loc['2017-08-10']\n",
        "\n",
        "# Get range\n",
        "df.loc['2014-01-20':'2014-01-22']\n",
        "\n",
        "# Get points in time by partial date\n",
        "df.loc['2012-02']\n",
        "df.loc['2012']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6PbSq3_lMTSO"
      },
      "source": [
        "# VISUALISING TIME SERIES\n",
        "\n",
        "# Display figures inline in Jupyter notebook\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Use seaborn style defaults and set the default figure size\n",
        "import seaborn as sns\n",
        "sns.set(rc={'figure.figsize':(11, 4)})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VB7kp17-MioG"
      },
      "source": [
        "# PLOTTING\n",
        "\n",
        "# Plotting based on Data Frame plot function\n",
        "df['Consumption'].plot(linewidth=0.5)\n",
        "\n",
        "# The plot() method has chosen pretty good tick locations (every two years) \n",
        "# and labels (the years) for the x-axis, which is helpful. \n",
        "# However, with so many data points, the line plot is crowded and hard to read. "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J4p9Drq1Oca4"
      },
      "source": [
        "# Let’s plot the data as dots instead, and also look at the Solar and Wind time series.\n",
        "cols_plot = ['Consumption', 'Solar', 'Wind']\n",
        "axes = df[cols_plot].plot(marker='.', alpha=0.5, linestyle=None, figsize=(11, 9), subplots=True)\n",
        "for ax in axes:\n",
        "  ax.set_ylabel('Daily Totals (GWh)')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uw2VGLYrOMft"
      },
      "source": [
        " # The plot above suggests there may be some weekly seasonality in Germany’s electricity consumption,\n",
        " # corresponding with weekdays and weekends. Let’s plot the time series in a single year to investigate further.\n",
        "\n",
        "# ax = opsd_daily.loc['2017', 'Consumption'].plot()\n",
        "ax = df.loc['2017', 'Consumption'].plot()\n",
        "ax.set_ylabel('Daily Consumption (GWh)');\n",
        "# Now, clearly we can see weekly oscilations"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2DBVg2Q9S7eN"
      },
      "source": [
        "# Another interesting feature that becomes apparent at this level of granularity is the drastic decrease\n",
        "# in electricity consumption in early January and late December, during the holidays.\n",
        "\n",
        "df.loc['2016-12':'2017-02', 'Consumption'].plot(marker='.', linestyle='-')\n",
        "ax.set_ylabel('Daily Consumption (GWh)');\n",
        "# As suspected, consumption is highest on weekdays and lowest on weekends."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "djLu96jBVXXR"
      },
      "source": [
        "# CUSTOMIZING TIME SERIES PLOTS\n",
        "\n",
        "# To better visualize the weekly seasonality in electricity consumption in the plot above, \n",
        "# it would be nice to have vertical gridlines on a weekly time scale (instead of on the first day of each month).\n",
        "# We can customize our plot with matplotlib.dates, so let’s import that module.\n",
        "import matplotlib.dates as mdates\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "ax.plot(df.loc['2016-12':'2017-02', 'Consumption'], marker='.', linestyle='-')\n",
        "ax.set_ylabel('Daily Consumption (GWh)')\n",
        "ax.set_title('Dec 2016 to Feb 2017 Electricity Consumption')\n",
        "ax.xaxis.set_major_locator(mdates.WeekdayLocator(byweekday=mdates.MONDAY))\n",
        "ax.xaxis.set_major_formatter(mdates.DateFormatter('%b %d'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6qK9ibR-X-Dz"
      },
      "source": [
        "# SEASONALITY\n",
        "\n",
        "# Boxplot chart explained:\n",
        "# https://towardsdatascience.com/understanding-boxplots-5e2df7bcbd51#:~:text=A%20boxplot%20is%20a%20standardized,%2C%20and%20%E2%80%9Cmaximum%E2%80%9D).&text=It%20can%20also%20tell%20you,how%20your%20data%20is%20skewed.\n",
        "\n",
        "# Let’s further explore the seasonality of our data with box plots, using seaborn’s boxplot() function\n",
        "# to group the data by different time periods and display the distributions for each group.\n",
        "\n",
        "# We’ll first group the data by month, to visualize yearly seasonality.\n",
        "fig, axes = plt.subplots(3, 1, figsize=(11, 10), sharex=True)\n",
        "for name, ax in zip(['Consumption', 'Solar', 'Wind'], axes):\n",
        "  sns.boxplot(data=df, x=\"Month\", y=name, ax=ax)\n",
        "  ax.set_ylabel('GWh')\n",
        "  ax.set_title(name)\n",
        "  # Remove the automatic x-axis label from all but the bottom subplot\n",
        "  if ax != axes[-1]:\n",
        "    ax.set_xlabel('')\n",
        "\n",
        "# Although electricity consumption is generally higher in winter and lower in summer, \n",
        "# the median and lower two quartiles are lower in December and January compared to November and February, \n",
        "# likely due to businesses being closed over the holidays. \n",
        "# We saw this in the time series for the year 2017, and the box plot confirms that this is consistent pattern throughout the years.\n",
        "\n",
        "# While solar and wind power production both exhibit a yearly seasonality, the wind power distributions have many more outliers, \n",
        "# reflecting the effects of occasional extreme wind speeds associated with storms and other transient weather conditions."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ZgTTOyIfs_P"
      },
      "source": [
        "# Electricity consumption weekly seasonality exploration\n",
        "sns.boxplot(data=df, x=\"Weekday Name\", y='Consumption')\n",
        "\n",
        "# As expected, electricity consumption is significantly higher on weekdays than on weekends. \n",
        "# The low outliers on weekdays are presumably during holidays."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "07YNif6PgymK"
      },
      "source": [
        "# FREQUENCIES\n",
        "\n",
        "# When the data points of a time series are uniformly spaced in time (e.g., hourly, daily, monthly, etc.), \n",
        "# the time series can be associated with a frequency in pandas. For example, let’s use the date_range() function \n",
        "# to create a sequence of uniformly spaced dates from 1998-03-10 through 1998-03-15 at daily frequency.\n",
        "\n",
        "# Sample daily frequency (see \"freq\" attribute with \"D\" value for daily)\n",
        "pd.date_range('1998-03-10', '1998-03-15', freq='D')\n",
        "\n",
        "# Hourly frequency with 8 data points\n",
        "pd.date_range('2004-09-20', periods=8, freq='H')\n",
        "\n",
        "# Now, let's take a look at time series frequency\n",
        "df.index\n",
        "# freq=None; This makes sense, since the index was created from a sequence of dates in our CSV file, \n",
        "# without explicitly specifying any frequency for the time series.\n",
        "\n",
        "# If we know that our data should be at a specific frequency, we can use the DataFrame’s asfreq() method to assign a frequency. \n",
        "# If any date/times are missing in the data, new rows will be added for those date/times, which are either empty (NaN), \n",
        "# or filled according to a specified data filling method such as forward filling or interpolation.\n",
        "times_samples = ['2013-02-03', '2013-02-06', '2013-02-08']\n",
        "consumption_samples = df.loc[times_samples, ['Consumption']].copy()\n",
        "consumption_samples\n",
        "\n",
        "# Create frequency without filing missing bits\n",
        "consumption_freq = consumption_samples.asfreq('D')\n",
        "# Create a column with missings forward filled\n",
        "consumption_freq['Consumption - Forward Fill'] = consumption_samples.asfreq('D', method='ffill')\n",
        "consumption_freq\n",
        "\n",
        "# In the Consumption - Forward Fill column, the missings have been forward filled,\n",
        "# meaning that the last value repeats through the missing rows until the next non-missing value occurs."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hnc9FL0_j7Mw"
      },
      "source": [
        "# RESAMPLING\n",
        "\n",
        "# It is often useful to resample our time series data to a lower or higher frequency. \n",
        "# Resampling to a lower frequency (downsampling) usually involves an aggregation operation — for example, \n",
        "# computing monthly sales totals from daily data. The daily OPSD data we’re working with in this tutorial was downsampled \n",
        "# from the original hourly time series. Resampling to a higher frequency (upsampling) is less common and often involves \n",
        "# interpolation or other data filling method — for example, interpolating hourly weather data to 10 minute intervals \n",
        "# for input to a scientific model.\n",
        "\n",
        "# Specify data columns we want to include\n",
        "data_columns = ['Consumption', 'Wind', 'Solar', 'Wind+Solar']\n",
        "df_weekly_mean = df[data_columns].resample('W').mean()\n",
        "df_weekly_mean.tail(3)\n",
        "\n",
        "print(df.shape[0])\n",
        "print(df_weekly_mean.shape[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oW-aL6jtnRkh"
      },
      "source": [
        "# Let's plot daily and weekly Solar consumption on single chart\n",
        "\n",
        "# start and end dates for extract\n",
        "start, end = '2017-01', '2017-06'\n",
        "# plot daily and weekly resampled time series together\n",
        "fig, ax = plt.subplots()\n",
        "ax.plot(df.loc[start:end, 'Solar'], marker='.', linestyle='-', linewidth=0.5, label='Daily')\n",
        "ax.plot(df_weekly_mean.loc[start:end, 'Solar'], marker='o', markersize=8, linestyle='-', label='Weekly Mean Resample')\n",
        "ax.set_ylabel('Solar Production GWh')\n",
        "ax.legend()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9CNtfy45pSw0"
      },
      "source": [
        "# Compute the monthly sums, setting the value to NaN for any month which has\n",
        "# fewer than 28 days of data\n",
        "df_monthly = df[data_columns].resample('M').sum(min_count=28)\n",
        "df_monthly.head(3)\n",
        "\n",
        "# Now let’s explore the monthly time series by plotting the electricity consumption \n",
        "# as a line plot, and the wind and solar power production together as a stacked area plot.\n",
        "fig, ax = plt.subplots()\n",
        "ax.plot(df_monthly['Consumption'], color='black', label='Consumption')\n",
        "df_monthly[['Wind', 'Solar']].plot.area(ax=ax, linewidth=0)\n",
        "ax.xaxis.set_major_locator(mdates.YearLocator())\n",
        "ax.legend()\n",
        "ax.set_ylabel('Monthly Total (GWh)');\n",
        "\n",
        "# At this monthly time scale, we can clearly see the yearly seasonality in each time series, \n",
        "# and it is also evident that electricity consumption has been fairly stable over time, \n",
        "# while wind power production has been growing steadily, with wind + solar power comprising an increasing \n",
        "# share of the electricity consumed."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-fGm50fYqrtt"
      },
      "source": [
        "# Let’s explore this further by resampling to annual frequency and computing the ratio of Wind+Solar to Consumption for each year.\n",
        "\n",
        "# Wind+Solar to Consumption for each year.\n",
        "# Compute the annual sums, setting the value to NaN for any year which has fewer than 360 days of data\n",
        "df_annual = df[data_columns].resample('A').sum(min_count=360)\n",
        "# The default index of the resampled DataFrame is the last day of each year,\n",
        "# ('2006-12-31', '2007-12-31', etc.) so to make life easier, set the index\n",
        "# to the year component\n",
        "df_annual = df_annual.set_index(df_annual.index.year)\n",
        "df_annual.index.name = 'Year'\n",
        "# Compute the ratio of Wind+Solar to Consumption\n",
        "df_annual['Wind+Solar/Consumption'] = df_annual['Wind+Solar'] / df_annual['Consumption']\n",
        "df_annual.tail(3)\n",
        "\n",
        "# Plot from 2012 onwards, because there is no solar production data in earlier years\n",
        "ax = df_annual.loc[2012:, 'Wind+Solar/Consumption'].plot.bar(color='C0')\n",
        "ax.set_ylabel('Fraction')\n",
        "ax.set_ylim(0, 0.3)\n",
        "ax.set_title('Wind+Solar Share of Annual Electricity Consumption')\n",
        "plt.xticks(rotation=0)\n",
        "\n",
        "# We can see that wind + solar production as a share of annual electricity consumption has been increasing \n",
        "# from about 15% in 2012 to about 27% in 2017."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ERj0wqleflNv"
      },
      "source": [
        "# ROLLING WINDOWS\n",
        "\n",
        "# Rolling window operations are another important transformation for time series data. Similar to downsampling, \n",
        "# rolling windows split the data into time windows and and the data in each window is aggregated with a function such as mean(), \n",
        "# median(), sum(), etc. However, unlike downsampling, where the time bins do not overlap and the output is at a lower frequency \n",
        "# than the input, rolling windows overlap and “roll” along at the same frequency as the data, so the transformed time series is \n",
        "# at the same frequency as the original time series.\n",
        "\n",
        "# By default, all data points within a window are equally weighted in the aggregation, but this can be changed by specifying window \n",
        "# types such as Gaussian, triangular, and others. We’ll stick with the standard equally weighted window here.\n",
        "\n",
        "# Let’s use the rolling() method to compute the 7-day rolling mean of our daily data. We use the center=True argument \n",
        "# to label each window at its midpoint.\n",
        "df_7d = df[data_columns].rolling(7, center=True).mean()\n",
        "df_7d.head(10)\n",
        "\n",
        "# We can see that the first non-missing rolling mean value is on 2006-01-04, because this is \n",
        "# the midpoint of the first rolling window."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bqv08ICDhFiq"
      },
      "source": [
        "# To visualize the differences between rolling mean and resampling, let’s update our earlier plot of January-June 2017 solar power \n",
        "# production to include the 7-day rolling mean along with the weekly mean resampled time series and the original daily data.\n",
        "\n",
        "start, end = '2017-01', '2017-06'\n",
        "# plot daily and weekly resampled time series together\n",
        "fig, ax = plt.subplots()\n",
        "ax.plot(df.loc[start:end, 'Solar'], marker='.', linestyle='-', linewidth=0.5, label='Daily')\n",
        "ax.plot(df_weekly_mean.loc[start:end, 'Solar'], marker='o', markersize=8, linestyle='-', label='Weekly Mean Resample')\n",
        "ax.plot(df_7d.loc[start:end, 'Solar'], marker='.', linestyle='-', label='7-d Rolling Mean')\n",
        "ax.set_ylabel('Solar Production GWh')\n",
        "ax.legend()\n",
        "\n",
        "# We can see that data points in the rolling mean time series have the same spacing as the daily data, but the curve \n",
        "# is smoother because higher frequency variability has been averaged out. In the rolling mean time series, the peaks and troughs \n",
        "# tend to align closely with the peaks and troughs of the daily time series. In contrast, the peaks and troughs in the weekly \n",
        "# resampled time series are less closely aligned with the daily time series, since the resampled time series is at a coarser \n",
        "# granularity."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sc844VzEigtL"
      },
      "source": [
        "# TRENDS\n",
        "\n",
        "# Time series data often exhibit some slow, gradual variability in addition to higher frequency variability such as seasonality \n",
        "# and noise. An easy way to visualize these trends is with rolling means at different time scales.\n",
        "\n",
        "# A rolling mean tends to smooth a time series by averaging out variations at frequencies much higher than the window size \n",
        "# and averaging out any seasonality on a time scale equal to the window size. This allows lower-frequency variations in the data \n",
        "# to be explored. Since our electricity consumption time series has weekly and yearly seasonality, let’s look at rolling means \n",
        "# on those two time scales.\n",
        "\n",
        "# We’ve already computed 7-day rolling means, so now let’s compute the 365-day rolling mean of our data.\n",
        "df_365d = df[data_columns].rolling(window=365, center=True, min_periods=360).mean()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "psHLL1Z5jOhR"
      },
      "source": [
        "# Plot daily, 7-day rolling mean, and 365-day rolling mean time series\n",
        "fig, ax = plt.subplots()\n",
        "ax.plot(df['Consumption'], marker='.', markersize=2, color='0.6', linestyle='None', label='Daily')\n",
        "ax.plot(df_7d['Consumption'], linewidth=2, label='7-d Rolling Mean')\n",
        "ax.plot(df_365d['Consumption'], color='0.2', linewidth=3, label='Trend (365-d Rolling Mean)')\n",
        "\n",
        "# Set x-ticks to yearly interval and add legend and labels\n",
        "ax.xaxis.set_major_locator(mdates.YearLocator())\n",
        "ax.legend()\n",
        "ax.set_xlabel('Year')\n",
        "ax.set_ylabel('Consumption (GWh)')\n",
        "ax.set_title('Trends in Electricity Consumption');\n",
        "\n",
        "# We can see that the 7-day rolling mean has smoothed out all the weekly seasonality, while preserving the yearly seasonality. \n",
        "# The 7-day rolling mean reveals that while electricity consumption is typically higher in winter and lower in summer, there is \n",
        "# a dramatic decrease for a few weeks every winter at the end of December and beginning of January, during the holidays.\n",
        "\n",
        "# Looking at the 365-day rolling mean time series, we can see that the long-term trend in electricity consumption is pretty flat, \n",
        "# with a couple of periods of anomalously low consumption around 2009 and 2012-2013."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PGGJrPcCkZiW"
      },
      "source": [
        "# Explore trends in wind and solar production\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "for name in ['Wind', 'Solar', 'Wind+Solar']:\n",
        "  ax.plot(df_365d[name], label=name)\n",
        "  ax.xaxis.set_major_locator(mdates.YearLocator())\n",
        "  ax.set_ylim(0, 400)\n",
        "  ax.legend()\n",
        "  ax.set_ylabel('Production (GWh)')\n",
        "  ax.set_title('Trends in Electricity Production (365-d Rolling Means)')\n",
        "\n",
        "  # We can see a small increasing trend in solar power production and a large increasing trend in wind power production, \n",
        "  # as Germany continues to expand its capacity in those sectors."
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}